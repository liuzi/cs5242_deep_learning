{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of ConvNets","version":"0.3.2","provenance":[{"file_id":"1AMsCM6Agsiz2WJe6yhBgtDVYtBcPPjnV","timestamp":1552292506202},{"file_id":"https://github.com/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb","timestamp":1551689304084}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"r2NPAI4jZZgi","colab_type":"text"},"cell_type":"markdown","source":["# ConvNets in Keras\n","\n","This notebook is adapted from [\"Classify Fashion-MNIST with a simple CNN in Keras\"](https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb#scrollTo=r2NPAI4jZZgi) by Margaret Maynard-Reid."]},{"metadata":{"id":"LbCigZtNZZgl","colab_type":"text"},"cell_type":"markdown","source":["## Install Tensorflow (keras) and Download the CIFAR10 data\n"]},{"metadata":{"id":"d44TznbgZZgm","colab_type":"code","colab":{}},"cell_type":"code","source":["# !pip install -q -U tensorflow>=1.8.0\n","import tensorflow as tf\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Load the fashion-mnist pre-shuffled train data and test data\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","\n","print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tWORMSC8FDR4","colab_type":"text"},"cell_type":"markdown","source":["## Visualize the data"]},{"metadata":{"id":"aFe4wHGRFKle","colab_type":"code","colab":{}},"cell_type":"code","source":["# Print training set shape - note there are 50,000 training data of image size of 32x32, 50,000 train labels)\n","print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n","\n","# Print the number of training and test datasets\n","print(x_train.shape[0], 'train set')\n","print(x_test.shape[0], 'test set')\n","\n","\n","# Image index, you can pick any number between 0 and 59,999\n","img_index = 5\n","# y_train contains the lables, ranging from 0 to 9\n","label_index = y_train[img_index]\n","\n","# # Show one of the images from the training dataset\n","plt.imshow(x_train[img_index])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zx-Ee6LHZZgt","colab_type":"text"},"cell_type":"markdown","source":["## Data normalization\n","Normalize the data dimensions so that they are of approximately the same scale."]},{"metadata":{"id":"XNh5NIckZZgu","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LMSg53fiZZgx","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"Number of train data - \" + str(len(x_train)))\n","print(\"Number of test data - \" + str(len(x_test)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CFlNHktHBtru","colab_type":"text"},"cell_type":"markdown","source":["## Split the data into train/validation/test data sets\n","\n","\n","*   Training data - used for training the model\n","*   Validation data - used for tuning the hyperparameters and evaluate the models\n","*   Test data - used to test the model after the model has gone through initial vetting by the validation set.\n","\n"]},{"metadata":{"id":"1ShU787gZZg0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n","(x_train, x_valid) = x_train[5000:], x_train[:5000] \n","(y_train, y_valid) = y_train[5000:], y_train[:5000]\n","\n","\n","# One-hot encode the labels\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","\n","# Print training set shape\n","print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n","\n","# Print the number of training, validation, and test datasets\n","print(x_train.shape[0], 'train set')\n","print(x_valid.shape[0], 'validation set')\n","print(x_test.shape[0], 'test set')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HhalcO03ZZg3","colab_type":"text"},"cell_type":"markdown","source":["## Create a simple ConvNet architecture\n","\n","There are two APIs for defining a model in Keras:\n","1. [Sequential model API](https://keras.io/models/sequential/)\n","2. [Functional API](https://keras.io/models/model/)\n","\n","In this notebook we are using the Functional API. \n","The [original notebook](https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb#scrollTo=QgTZ47SsZZg4) uses Sequential API."]},{"metadata":{"id":"p4aRr_GrbwOV","colab_type":"code","colab":{}},"cell_type":"code","source":["class Foo:\n","    \n","    def __init__(self, name):\n","        self.name=name\n","    \n","    def __call__(self, x):\n","        print(self.name, x)\n","    \n","    \n","Foo('aa')('bb')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QgTZ47SsZZg4","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow import keras\n","\n","inputs = keras.Input(shape=(32, 32, 3)) \n","x = keras.layers.Conv2D(filters=6, kernel_size=5, padding='valid', activation='relu')(inputs)\n","x = keras.layers.MaxPooling2D(pool_size=2)(x)\n","x = keras.layers.Conv2D(filters=16, kernel_size=5, padding='valid', activation='relu')(x)\n","x = keras.layers.MaxPooling2D(pool_size=2)(x)\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(120, activation='relu')(x)\n","x = keras.layers.Dense(84, activation='relu')(x)\n","x = keras.layers.Dense(10, activation='softmax')(x)\n","\n","model = keras.Model(inputs=inputs, outputs=x)\n","# Take a look at the model summary\n","model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FhxJ5dinZZg8","colab_type":"text"},"cell_type":"markdown","source":["## Compile the model\n","Configure the learning process with compile() API before training the model. It receives three arguments:\n","\n","*   An optimizer \n","*   A loss function \n","*   A list of metrics \n"]},{"metadata":{"id":"CQUlOa8cZZg9","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(loss='categorical_crossentropy',\n","             optimizer='adam',\n","             metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DtOvh3YVZZg_","colab_type":"text"},"cell_type":"markdown","source":["## Train the model\n","\n","Now let's train the model with fit() API.\n","\n","We use  the [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) API to save the model after every epoch. Set \"save_best_only = True\" to save only when the validation accuracy improves.\n"]},{"metadata":{"id":"ZTmapAttZZhA","colab_type":"code","colab":{}},"cell_type":"code","source":["model.fit(x_train,\n","         y_train,\n","         batch_size=64,\n","         epochs=10,\n","         validation_data=(x_valid, y_valid))\n","         #callbacks=[checkpointer])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9RTRkan4yq5H","colab_type":"text"},"cell_type":"markdown","source":["## Test Accuracy"]},{"metadata":{"id":"VZtqBqFFy62R","colab_type":"code","colab":{}},"cell_type":"code","source":["# Evaluate the model on test set\n","score = model.evaluate(x_test, y_test, verbose=0)\n","\n","# Print test accuracy\n","print('\\n', 'Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d7GASPXU_iN8","colab_type":"text"},"cell_type":"markdown","source":["## AlexNet architecture\n","\n","A [variant of AlexNet](https://github.com/bearpaw/pytorch-classification/blob/master/models/cifar/alexnet.py) for CIFAR10 data."]},{"metadata":{"id":"s36CsG1Q_lOY","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow import keras\n","\n","inputs = keras.Input(shape=(32, 32, 3)) \n","\n","x = keras.layers.Conv2D(filters=64, kernel_size=11, strides=4, padding='same', activation='relu')(inputs)\n","x = keras.layers.MaxPooling2D(pool_size=2)(x)\n","x = keras.layers.Conv2D(filters=192, kernel_size=5, padding='same', activation='relu')(x)\n","x = keras.layers.MaxPooling2D(pool_size=2)(x)\n","x = keras.layers.Conv2D(filters=384, kernel_size=3, padding='same', activation='relu')(x)\n","x = keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x)\n","x = keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x)\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(256, activation='relu')(x)\n","x = keras.layers.Dense(10, activation='softmax')(x)\n","\n","\n","\n","\n","model = keras.Model(inputs=inputs, outputs=x)\n","# Take a look at the model summary\n","model.summary()\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uODkYBJkAmMU","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(loss='categorical_crossentropy',\n","             optimizer='adam',\n","             metrics=['accuracy'])\n","model.fit(x_train,\n","         y_train,\n","         batch_size=64,\n","         epochs=10,\n","         validation_data=(x_valid, y_valid))\n","         #callbacks=[checkpointer])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f17o694eAytb","colab_type":"text"},"cell_type":"markdown","source":["# VGG architecture\n","\n","[The sequential API version](https://github.com/geifmany/cifar-vgg/blob/master/cifar10vgg.py)\n","\n","[Keras official implementation](https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py)"]},{"metadata":{"id":"dm7s1fxyA3WS","colab_type":"code","colab":{}},"cell_type":"code","source":["def ConvBlock(nb_kernels, drop_rate, pooling, x):\n","    x=keras.layers.Conv2D(nb_kernels, 3, padding='same', activation='relu')(x)    \n","    if drop_rate > 0:\n","        x=keras.layers.Dropout(drop_rate)(x)\n","    if pooling:\n","        x=keras.layers.MaxPooling2D(pool_size=2)(x)\n","    return x\n","\n","\n","x = ConvBlock(64, 0.3, False, x)\n","x = ConvBlock(64, 0, True, x)\n","x = ConvBlock(128, 0.4, False, x)\n","x = ConvBlock(128, 0, True, x)\n","x = ConvBlock(256, 0.4, False, x)\n","x = ConvBlock(256, 0.4, False, x)\n","x = ConvBlock(256, 0, True, x)\n","x = ConvBlock(512, 0.4, False, x)\n","x = ConvBlock(512, 0.4, False, x)\n","x = ConvBlock(512, 0, True, x)\n","x = ConvBlock(512, 0.4, False, x)\n","x = ConvBlock(512, 0.4, False, x)\n","x = ConvBlock(512, 0, True, x)\n","x = keras.layers.Dropout(0.5)(x)\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(512, activation='relu')(x)\n","x = keras.layers.Dropout(0.5)(x)\n","x = keras.layers.Dense(10, activation='softmax')(x)\n","model = keras.Model(inputs=inputs, outputs=x)\n","# Take a look at the model summary\n","model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"56QTuY_sEAyk","colab_type":"text"},"cell_type":"markdown","source":["# InceptionNet\n","\n","[Keras implementation](https://github.com/keras-team/keras-applications/blob/master/keras_applications/inception_v3.py)"]},{"metadata":{"id":"hDNZU7MaEU30","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing import image\n","from keras.applications.inception_v3 import preprocess_input\n","from keras.models import Model\n","import numpy as np\n","\n","base_model = InceptionV3(weights='imagenet')\n","model = Model(inputs=base_model.input, outputs=base_model.get_layer('mixed4').output)\n","\n","img_path = '10155.jpg'\n","img = image.load_img(img_path, target_size=(299, 299))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","features = model.predict(x)\n","print(features.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YkCAiRJKEVU_","colab_type":"text"},"cell_type":"markdown","source":["# ResNet\n","\n","\n","[Keras implementation](https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py)"]},{"metadata":{"id":"vAlzbIMMEWY5","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.applications.resnet50 import ResNet50\n","from keras.preprocessing import image\n","from keras.applications.resnet50 import preprocess_input, decode_predictions\n","import numpy as np\n","\n","model = ResNet50(weights='imagenet')\n","\n","img_path = '10155.jpg'\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","preds = model.predict(x)\n","# decode the results into a list of tuples (class, description, probability)\n","# (one such list for each sample in the batch)\n","print('Predicted:', decode_predictions(preds, top=3)[0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YnGF1EV0HV1y","colab_type":"code","colab":{}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rnnVpEVcEcIH","colab_type":"text"},"cell_type":"markdown","source":["XceptionNet\n","\n"]},{"metadata":{"id":"3o2axVRNGvvv","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}